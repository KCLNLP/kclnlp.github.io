<!DOCTYPE html>
<html lang="en">

<head>
    <title>King's College London NLP</title>
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico" />
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css"
        integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
    <link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="./styles.css">
    <style>
        body,
        h1,
        h2,
        h3,
        h4,
        h5,
        h6 {
            font-family: "Lato", sans-serif
        }

        .w3-bar,
        h1,
        button {
            font-family: "Montserrat", sans-serif
        }

        .fa-anchor,
        .fa-coffee {
            font-size: 200px
        }

        .homebackground {
            background-image: url('./pictures/background/home.webp');
            overflow: hidden;
        }

        .maintopic {
            margin-top: 150px;
            color: white;
            font-size: 65px;
            text-align: left;
        }

        .topic {
            margin-top: 10px;
            color: white;
            font-size: 35px;
            text-align: left;
        }

        .jumpbutton {
            background-color: rgba(43, 43, 43, 0.9);
            border: none;
            color: white;
            padding: 15px 32px;
            text-align: center;
            text-decoration: none;
            display: inline-block;
            font-size: 16px;
            margin: 4px 2px;
            cursor: pointer;
        }

        .maintitle {
            margin-top: 10px;
            color: rgba(98, 73, 31, 0.691);
            font-size: 45px;
            text-align: left;
            background-color: white;
        }

        .maintitle:after {
            background-color: grey;
            content: '';
            display: block;
            position: absolute;
            top: 10px;
            left: 10px;
            right: 10px;
            bottom: 10px;
            z-index: -1;
        }

        .maintext {
            color: rgb(107, 107, 107);
            font-size: 17px;
            text-align: left;
        }

        .background1 {
            background-color: rgba(76, 83, 82, 0.2)
        }

        .toptopic {
            width: 100%;
            background-color: rgb(49, 49, 49);
            z-index: 100;
        }

        .navbarbutton {
            background-color: black;
            border: none;
            color: white;
            padding: 15px 32px;
            text-align: center;
            text-decoration: none;
            display: inline-block;
            font-size: 16px;
            margin: 4px 2px;
            cursor: pointer;
        }

        .logo {
            margin: 10px;
            display: table-cell;
            vertical-align: middle;
            text-align: center
        }

        .backgroundlayer {
            margin-left: 15%;
            width: 70%;
        }

        li.space {
            margin: 10px 0;
        }

        .paper-box {
            border-color: rgba(98, 73, 31, 0.5);
            margin: 1%;
            border-style: solid;
            height: 300px;
            overflow: hidden;
            border-radius: 8px;
        }

        button {
            --b: 3px;
            /* border thickness */
            --s: .15em;
            /* size of the corner */
            --c: #BD5532;

            padding: calc(.05em + var(--s)) calc(.3em + var(--s));
            color: var(--c);
            --_p: var(--s);
            background:
                conic-gradient(from 90deg at var(--b) var(--b), #0000 90deg, var(--c) 0) var(--_p) var(--_p)/calc(100% - var(--b) - 2*var(--_p)) calc(100% - var(--b) - 2*var(--_p));
            transition: .3s linear, color 0s, background-color 0s;
            outline: var(--b) solid #0000;
            outline-offset: .2em;
        }

        button:hover,
        button:focus-visible {
            --_p: 0px;
            outline-color: var(--c);
            outline-offset: .05em;
        }

        button:active {
            background: var(--c);
            color: #fff;
        }

        button {
            font-family: system-ui, sans-serif;
            font-weight: bold;
            font-size: 15px;
            cursor: pointer;
            border: none;
            margin: .1em;
        }

        .container {
            display: table;
            text-align: center;
        }

        .container>.child {
            display: table-cell;
            vertical-align: middle;
        }

        .subtitle {
            margin-top: 10px;
            color: rgba(98, 73, 31, 0.691);
            font-size: 25px;
            text-align: left;
            padding-top: 5px;
            background-color: white;
        }
    </style>
</head>


<body>

    <!-- Navbar -->

    <div class="w3-top toptopic">
        <div class="col-xs-3">
            <div style="height: 10px;"></div>
            <b style="color: rgb(219, 219, 219); font-size: 25px; height: 40px; margin-left: 10px;">
                King's College London NLP </b>
            <div style="height: 2px;"></div>
        </div>
        <div class="col-xs-9">

            <ul class="nav nav-pills">
                <li class="nav-item">
                    <a class="nav-link" aria-current="page" href="./about.html">About</a>
                </li>
                <li class="nav-item  active font-weight-bold">
                    <a class="nav-link" aria-current="page" href="./research.html">Research</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" aria-current="page" href="./projects.html">Projects</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" aria-current="page" href="./activities.html">Activities</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" aria-current="page" href="./team.html">Team</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" aria-current="page" href="./publications.html">Publications</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" aria-current="page" href="./resource.html">Resource</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" aria-current="page" href="./contact.html">Contact</a>
                </li>
            </ul>
        </div>
    </div>


    <!-- Header -->
    <div class="backgroundlayer  col-xs-12" style="margin-top: 120px;">
        <div class="col-xs-9 maintitle">
            <div><b>Narrative Understanding with LLMs</b></div>

            <div class="subtitle"><b>Introduction</b></div>
            <div class="maintext">
				<p>
					Narrative stories are characterised by their extended length
					and depth. They consist of elements such as the viewpoint or
					perspective from which the story is told, the characters
					involved, and events that happened. All of these come together
					to create a cohesive plot, whether it is in a book, a movie, or
					other form of storytelling. Narrative understanding involves
					comprehending these elements, how they connect or influence
					each other, how the relationships between the characters change
					over time, how events cause other events to happen, and how
					events are interwoven to shape the narrative’s progression.
				</p>

				<p>
					LLMs have demonstrated their impressive capabilities in
					generating human-like language. However, using LLMs for
					narratives understanding faces several challenges. For example,
					LLMs have a difficulty in dealing with long narrative text.
					Events or characters introduced early on in a narrative may
					have a significant impact on later events. Also, relationships
					among characters are not fixed and may evolve over time. LLMs
					may struggle to monitor and capture these evolving
					relationships. Furthermore, narratives often involve causal
					relationships among events, characters, and actions. Extracting
					and correctly inferring these causal links can be challenging
					for LLMs, as it requires understanding not only what happened
					but also why and how events are connected. Narrative
					understanding also requires the ability of inferring the
					emotional states of characters, their motivations and
					intentions. This requires LLMs to possess the Theory of Mind
					(ToM) capabilities. The question of whether LLMs can be trained
					to develop such ToM capabilities remains open. Another
					challenging task for LLMs is to accurately extract plots from
					complex narratives, where they can have plots with multiple
					storylines, flashbacks, or non-linear structures. Identifying
					and presenting storylines in a coherent manner can be a
					significant challenge for LLMs.
				</p>
			</div>

            <div class="subtitle"><b>Projects</b></div>
            <div class="maintext">
				<ul>
					<li>
						<a href="https://gow.epsrc.ukri.org/NGBOViewGrant.aspx?GrantRef=EP/V020579/1">
							Event-Centric Framework for Natural Language Understanding
						</a> (Jan 2021-Dec 2025), Turing AI Fellowship, funded by the UKRI.
					</li>
					<li>
						Character-Centric Narrative Understanding, (2023-2027), funded by EPSRC ICASE, with Huawei London Research
						Centre.
					</li>
					<li>
						<a href="https://gtr.ukri.org/projects?ref=EP%2FX019063%2F1">
							A Lebesgue Integral based Approximation for Language Modelling
						</a> (2023-2025), funded by the EPSRC.
					</li>
				</ul>
			</div>

            <div class="subtitle"><b>Project Aims</b></div>
            <div class="maintext">
				<p>Our project aims are:</p>

				<ul>
					<li>
						<b>Character-centric analysis</b>. We aim to develop automated
						approaches for identifying key characters, their roles,
						characteristics, and relationships within a narrative. This
						involves tackling challenges such as character co-referencing
						and linking. Also, detecting relationships among characters may
						require addressing conflict and incomplete information in
						narratives and tracking dynamic character relationships.
					</li>

					<li>
						<b>Story map extraction</b>. Traditionally, events in a storyline
						usually follow a chronological order. However, in narratives,
						stories are complex. Narrative could be structured in many ways
						including flashbacks, multiple stories happening
						simultaneously, many smaller stories taking place within a
						bigger plot, or even interwoven stories. We aim to develop
						automated approaches for story map extraction.
					</li>

					<li>
						<b>Reasoning in narratives</b>. We aim to enhance LLMs’ capabilities
						to reason about the temporal order of events and their
						relationships in narratives. We will also explore approaches to
						enable LLMs to understanding cause-and-effect relationships and
						perform theory-of-mind reasoning within narratives.
					</li>

					<li>
						<b>Interactive narrative understanding</b>. We will investigate a
						framework for interactive narrative understanding, which will
						involve a few key components, including (1) Agents – extracting
						comprehensive character-centric memory from narratives,
						including aspects such as character’s personal traits and
						preferences, beliefs and desires, their relationships with
						other characters, their emotional states, their past
						behaviours, and their anticipated actions. (2) Settings –
						identifying character locations and settings, which are often
						vaguely defined unless crucial to the plot. (3) Responses –
						ensuring consistency and engagement in user interactions,
						despite varying user inputs.
					</li>
				</ul>
			</div>

            <div class="subtitle"><b>Applications</b></div>
            <div class="maintext">
				<p>
					Narrative understanding can find a wide variety of
					applications. Some example applications are listed below:
				</p>

				<ul>
					<li>
						<b>Personalised interactive narrative storytelling</b>. Creating
						immersive and interactive narrative environments tailored
						to individual preferences, resembling the dynamic
						storylines experienced by individuals, as depicted in the
						TV series “Westworld”.
					</li>

					<li>
						<b>ESG report analysis</b>. Deriving insights from lengthy ESG
						reports, which convey comprehensive and data-driven
						narratives about companies’ performance and initiatives
						related to environmental sustainability, social
						responsibility, and corporate governance.
					</li>

					<li>
						<b>News storyline generation</b>. In platforms like news aggregators, narrative
						understanding could improve content relevance and
						engagement by generating more coherent and informative news
						storylines.
					</li>

					<li>
						<b>Consistent and long-range conversations with LLM chatbots</b>. Long
						conversations with LLM-based chatbots can be considered as
						a form of narrative storytelling, although it is
						interactive and dynamically generated. Such long-range
						conversations that involve diverse topics presents a
						challenge for conventional methods, as they struggle to
						effectively address the issue of retaining contextual
						coherence over long stretches of discourse.
					</li>
				</ul>
			</div>

            <div class="subtitle"><b>Participants</b></div>
            <div class="maintext">
				Lin Gui, Jiazheng Li, Junru Lu, Gabriele Pergola, Zhaoyue, Sun,
				Xingwei Tan, Xinyu, Wang, Hainiu Xu, Wenjia Zhang, Runcong
				Zhao, Yuxiang Zhou, Lixing Zhu, Qinglin Zhu
            </div>
        </div>
        <div class="col-xs-3">
            <div class="col-xs-12 logo">
                <img src="./pictures/logo/KCLNLP.png" alt="Challenges" style="width:150px">
            </div>
            <div class="col-xs-12 logo">
                <img src="./pictures/logo/KCL.png" alt="Challenges" style="width:210px">
            </div>
        </div>
    </div>

    <div class="backgroundlayer  col-xs-12" style="margin-top: 0px;">
        <div class="col-xs-12 maintitle">
            <div class="subtitle"><b>Publications (since 2021)</b></div>
            <div class="maintext">
                <ul>
					<li class="space">
						H. Xu, R. Zhao, L. Zhu, J. Du, Y. He.
						<a href="https://arxiv.org/abs/2402.06044">
							OpenToM: A Comprehensive Benchmark for Evaluating Theory-of-Mind Reasoning Capabilities of Large Language Models
						</a>,
						<em>arXiv:2402.06044, 2024.</em>
						<a href="https://seacowx.github.io/projects/opentom/OpenToM.html">[Website]</a>
						<a href="https://huggingface.co/datasets/SeacowX/OpenToM">[Dataset]</a>
					</li>
					<li class="space">
						R. Zhao, W. Zhang, J. Li, L. Zhu, Y. Li, Y. He and L. Gui.
						<a href="https://arxiv.org/abs/2310.01459">
							NarrativePlay: Interactive Narrative Understanding
						</a>,
						<em>The 18th Conference of the European Chapter of the Association for Computational Linguistics</em> (<b>EACL</b>), 2024.
					</li>
					<li class="space">
						R. Zhao, W. Zhang, J. Li, L. Zhu, Y. Li, Y. He and L. Gui.
						<a href="">
							NarrativePlay: An Automated System for Crafting Visual Worlds in Novels for Role-Playing
						</a>,
						<em>The 38th Annual AAAI Conference on Artificial Intelligence</em> (<b>AAAI</b>), 2024.
					</li>
					<li class="space">
						X. Wang, L. Gui and Y. He.
						<a href="https://arxiv.org/abs/2310.18073">
							A Scalable Framework for Table of Contents Extraction from Complex ESG Annual Reports
						</a>,
						<em>The 2023 Conference on Empirical Methods in Natural Language Processing</em> (<b>EMNLP</b>), 2023.
					</li>
					<li class="space">
						L. Zhu, R. Zhao, L. Gui and Y. He.
						<a href="https://arxiv.org/abs/2310.18783">Are NLP Models Good at Tracing Thoughts: An Overview of Narrative Understanding</a>,
						<em>Findings of EMNLP</em>, 2023.
					</li>
                    <li class="space">
                        J. Lu, S. An, M. Lin, G. Pergola, Y. He, D. Yin, X. Sun and Y. Wu.
                        <a href="https://arxiv.org/abs/2308.08239">MemoChat: Tuning LLMs to Use Memos for Consistent Long-Range Open-Domain Conversation</a>,
                        <em>arXiv:2308.08239.</em>
                    </li>

                    <li class="space">
                        J. Lu, G. Pergola, L. Gui and Y. He.
                        <a href="https://arxiv.org/abs/2305.04522">Event Knowledge Incorporation with Posterior Regularization for Event-Centric Question Answering</a>,
                        <em>arXiv:2305.04522.</em>
                    </li>

                    <li class="space">
                        X. Wang, L. Gui and Y. He.
                        <a href="">Document-Level Multi-Event Extraction with Event Proxy Nodes and Hausdorff Distance Minimization</a>,
                        <em>The 61st Annual Meeting of the Association for Computational Linguistics </em>
                        (<b>ACL</b>), Jul. 2023.
                    </li>

                    <li class="space">
                        X. Tan, G. Pergola and Y. He.
                        <a href="https://arxiv.org/abs/2302.04985"> Event Temporal Relation Extraction with Bayesian Translational Model</a>,
                        <em>The 17th Conference of the European Chapter of the Association for Computational Linguistics </em>
                        (<b>EACL</b>), May. 2023.
                    </li>

                    <li class="space">
                        J. Lu, J. Li, B.C. Wallace, Y. He and G. Pergola.
                        <a href="https://arxiv.org/abs/2302.05574">NapSS: Paragraph-level Medical Text Simplification via
                            Narrative Prompting and Sentence-matching Summarization</a>,
                        <em>Findings of EACL</em>, May. 2023.
                    </li>

                    <li class="space">
                        H. Li, H. Yan, Y. Li, L. Qian, Y. He and L. Gui.
                        <a href="https://arxiv.org/abs/2302.06198">Distinguishability Calibration to In-Context Learning</a>,
                        <em>Findings of EACL</em>, May. 2023.
                    </li>

                    <li class="space">
                        Z. Sun, J. Li, G. Pergola, B.C. Wallace, B. John, N. Greene, J. Kim and Y. He.
                        <a href="https://arxiv.org/abs/2210.12560">PHEE: A Dataset for Pharmacovigilance Event Extraction
                            from Text</a>,
                        <em>The 2022 Conference on Empirical Methods in Natural Language Processing </em> (<b>EMNLP</b>),
                        Dec. 2022.
                    </li>

                    <li class="space">
                        J. Lu, X. Tan, G. Pergola, L. Gui and Y. He.
                        <a href="https://arxiv.org/abs/2210.12902#">Event-Centric Question Answering via Contrastive Learning
                            and Invertible Event Transformation</a>,
                        <em>Findings of EMNLP</em>, Dec. 2022.
                    </li>

                    <li class="space">
                        H. Yan, L. Gui and Y. He.
                        <a
                            href="https://direct.mit.edu/coli/article/48/4/987/112768/Hierarchical-Interpretation-of-Neural-Text">Hierarchical
                            Interpretation of Neural Text
                            Classification</a>,
                        <em>Computational Linguistics</em>, to appear.
                    </li>

                    <li class="space">
                        H. Yan, L. Gui, W. Li ad Y. He.
                        <a href="https://openreview.net/forum?id=BtUxE_8i5l5">Addressing Token
                            Uniformity in Transformers via Singular Value Transformation</a>,
                        <em>38th Conference on Uncertainty in Artificial Intelligence</em> (<b>UAI</b>), Aug. 2022.
                    </li>

                    <li class="space">
                        R. Adewoyin, R. Dutta and Y. He.
                        <a href="https://openreview.net/forum?id=BtUxE_8i5l5">RSTGen: Imbuing Fine-Grained Interpretable Control into Long-FormText Generators</a>,
                        <em>2022 Annual Conference of the North American Chapter of the Association for Computational Linguistics</em> (<b>NAACL</b>), Jul. 2022.
                    </li>

                    <li class="space">
                        X. Tan, G. Pergola and Y. He.
                        <a href="https://aclanthology.org/2021.emnlp-main.636/">Extracting Event Temporal Relations via Hyperbolic Geometry</a>,
                        <em>Conference on Empirical Methods in Natural Language Processing</em>
                        (<b>EMNLP</b>), Nov. 2021.
                    </li>

                    <li class="space">
                        L. Zhu, G. Pergola, L. Gui, D. Zhou and Y. He.
                        <a href="https://arxiv.org/abs/2106.01071v1">Topic-Driven and Knowledge-Aware Transformer for Dialogue Emotion Detection</a>,
                        <em>The 59th Annual Meeting of the Association for Computational Linguistics</em>
                        (<b>ACL</b>), Aug. 2021.
                    </li>

                    <li class="space">
                        L. Zhang, D. Zhou, Y. He and Z. Yang.
                        <a href="https://ojs.aaai.org/index.php/AAAI/article/view/17695">MERL: Multimodal Event Representation Learning in Heterogeneous Embedding Spaces</a>,
                        <em>The 35th AAAI Conference on Artificial Intelligence</em>
                        (<b>AAAI</b>), Feb. 2021.
                    </li>



                </ul>

            </div>
        </div>
        <div id="applications" class="col-xs-3" style="height: 20px; width: 100%;"></div>
    </div>


    <div id="projectaims" class="col-xs-3" style="height: 200px; width: 100%;"></div>





    <div class="w3-bottom w3-container w3-grey w3-center w3-opacity">
        <h5 class="w3-margin">© 2024 Copyright: KCL NLP Group </h5>
    </div>

    <script type="text/javascript">
        function scrollto(element) {
            console.log(3);
            // get the element on the page related to the button
            var scrollToId = element.getAttribute("data-scroll");
            document.getElementById(scrollToId).scrollIntoView({ block: "end", behavior: "smooth" });
            console.log(scrollToId);
        }
    </script>

</body>

</html>
